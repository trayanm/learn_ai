{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ec6d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04259798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = \"adult_income.csv\"\n",
    "if not os.path.exists(data_path):\n",
    "    df = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "        header=None,\n",
    "        names=[\n",
    "            \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "            \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "            \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "        ]\n",
    "    )\n",
    "    df.to_csv(data_path, index=False)\n",
    "else:\n",
    "    df = pd.read_csv(\n",
    "        data_path,\n",
    "        header=None,\n",
    "        names=[\n",
    "            \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "            \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "            \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "report_data_path = \"adult_income_profile_report.html\"\n",
    "\n",
    "if not os.path.exists(report_data_path):\n",
    "    profile = ProfileReport(df, title=\"Adult Income Dataset Profile Report\", explorative=True)\n",
    "    profile.to_file(\"adult_income_profile_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70bbf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  drop columns with missing values\n",
    "df.replace(\" ?\", np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46634c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
      "Numerical columns: []\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"income\", axis=1)\n",
    "y = df[\"income\"].apply(lambda x: x.strip() == \">50K\")\n",
    "\n",
    "# identity column types\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude=\"object\").columns.tolist()\n",
    "\n",
    "print(f\"Categorical columns: {cat_cols}\")\n",
    "print(f\"Numerical columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "670e6aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0de898a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: One-hot fpr categorical, scale for numerical\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    (\"scale\", StandardScaler(), num_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df43a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=2000, solver=\"lbfgs\", n_jobs=-1),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, n_jobs=-1),\n",
    "    \"MLPClassifier\": MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=400),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3f8b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(name, model):\n",
    "    result = {}\n",
    "\n",
    "    print(f\"\\nRunning pipeline for {name}...\")\n",
    "\n",
    "    pipeline = make_pipeline(preprocessor, model)\n",
    "\n",
    "    # Fit\n",
    "    start_time = time.perf_counter()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    fit_time = time.perf_counter() - start_time\n",
    "\n",
    "    # Save model to disk\n",
    "    filename = f\"{name}.joblib\"\n",
    "    joblib.dump(pipeline, filename)\n",
    "    model_size_kb = os.path.getsize(filename) / 1024\n",
    "\n",
    "    # Inference timing (single-row prediction)\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in range(1000):\n",
    "        pipeline.predict(X_test.iloc[[0]])  # Correct: 2D input\n",
    "    latency_ms = (time.perf_counter() - start_time) / 1000 * 1000\n",
    "    # accuracy\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    result = {\n",
    "        \"Train Time (s)\": round(fit_time, 3),\n",
    "        \"Latency (ms)\": round(latency_ms, 3),\n",
    "        \"Model Size (KB)\": round(model_size_kb, 1),\n",
    "        \"Accuracy\": round(acc * 100, 2),\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def print_result(model_name, result):\n",
    "    print(\"\\nModel Benchmark Results:\\n\")\n",
    "    print(\n",
    "        \"{:<18} {:>15} {:>15} {:>18} {:>12}\".format(\n",
    "            \"Model\", \"Train Time (s)\", \"Latency (ms)\", \"Model Size (KB)\", \"Accuracy (%)\"\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    print(\n",
    "        \"{:<18} {:>15} {:>15} {:>18} {:>12}\".format(\n",
    "            model_name,\n",
    "            result[\"Train Time (s)\"],\n",
    "            result[\"Latency (ms)\"],\n",
    "            result[\"Model Size (KB)\"],\n",
    "            result[\"Accuracy\"],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "792d803c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running pipeline for LogisticRegression...\n",
      "\n",
      "Model Benchmark Results:\n",
      "\n",
      "Model               Train Time (s)    Latency (ms)    Model Size (KB) Accuracy (%)\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression          11.631          22.767              296.2        86.03\n",
      "\n",
      "Running pipeline for RandomForest...\n",
      "\n",
      "Model Benchmark Results:\n",
      "\n",
      "Model               Train Time (s)    Latency (ms)    Model Size (KB) Accuracy (%)\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForest                13.093          76.521           243419.0        84.83\n",
      "\n",
      "Running pipeline for MLPClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:788: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Benchmark Results:\n",
      "\n",
      "Model               Train Time (s)    Latency (ms)    Model Size (KB) Accuracy (%)\n",
      "--------------------------------------------------------------------------------\n",
      "MLPClassifier              344.885         1829.42            71318.1        82.89\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    result = run_pipeline(name, model)\n",
    "    print_result(name, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
