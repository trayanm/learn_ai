{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec6d279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04259798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 413.38it/s]<00:01,  5.47it/s, Describe variable: income]\n",
      "Summarize dataset: 100%|██████████| 60/60 [00:05<00:00, 10.35it/s, Completed]                             \n",
      "Generate report structure: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 92.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_path = \"adult_income.csv\"\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    df = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "        header=None,\n",
    "        names=[\n",
    "            \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "            \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "            \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "        ]\n",
    "    )\n",
    "    df.to_csv(data_path, index=False)\n",
    "else:\n",
    "    df = pd.read_csv(\n",
    "        data_path,\n",
    "        header=None,\n",
    "        names=[\n",
    "            \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "            \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "            \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "report_data_path = \"adult_income_profile_report.html\"\n",
    "\n",
    "if not os.path.exists(report_data_path):\n",
    "    profile = ProfileReport(df, title=\"Adult Income Dataset Profile Report\", explorative=True)\n",
    "    profile.to_file(\"adult_income_profile_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70bbf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  drop columns with missing values\n",
    "df.replace(\" ?\", np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46634c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
      "Numerical columns: ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"income\", axis=1)\n",
    "y = df[\"income\"].apply(lambda x: x.strip() == \">50K\")\n",
    "\n",
    "# identity column types\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude=\"object\").columns.tolist()\n",
    "\n",
    "print(f\"Categorical columns: {cat_cols}\")\n",
    "print(f\"Numerical columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670e6aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0de898a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: One-hot fpr categorical, scale for numerical\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    (\"scale\", StandardScaler(), num_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df43a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=2000, solver=\"lbfgs\", n_jobs=-1),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, n_jobs=-1),\n",
    "    \"MLPClassifier\": MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=400),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f8b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(name, model):\n",
    "    result = {}\n",
    "\n",
    "    print(f\"\\nRunning pipeline for {name}...\")\n",
    "\n",
    "    pipeline = make_pipeline(preprocessor, model)\n",
    "\n",
    "    # Fit\n",
    "    start_time = time.perf_counter()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    fit_time = time.perf_counter() - start_time\n",
    "\n",
    "    # Save model to disk\n",
    "    filename = f\"{name}.joblib\"\n",
    "    joblib.dump(pipeline, filename)\n",
    "    model_size_kb = os.path.getsize(filename) / 1024\n",
    "\n",
    "    # Inference timing (single-row prediction)\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in range(1000):\n",
    "        pipeline.predict(X_test.iloc[[0]])  # Correct: 2D input\n",
    "    latency_ms = (time.perf_counter() - start_time) / 1000 * 1000\n",
    "    # accuracy\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    result = {\n",
    "        \"Train Time (s)\": round(fit_time, 3),\n",
    "        \"Latency (ms)\": round(latency_ms, 3),\n",
    "        \"Model Size (KB)\": round(model_size_kb, 1),\n",
    "        \"Accuracy\": round(acc * 100, 2),\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def print_result(model_name, result):\n",
    "    print(\"\\nModel Benchmark Results:\\n\")\n",
    "    print(\n",
    "        \"{:<18} {:>15} {:>15} {:>18} {:>12}\".format(\n",
    "            \"Model\", \"Train Time (s)\", \"Latency (ms)\", \"Model Size (KB)\", \"Accuracy (%)\"\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    print(\n",
    "        \"{:<18} {:>15} {:>15} {:>18} {:>12}\".format(\n",
    "            model_name,\n",
    "            result[\"Train Time (s)\"],\n",
    "            result[\"Latency (ms)\"],\n",
    "            result[\"Model Size (KB)\"],\n",
    "            result[\"Accuracy\"],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "792d803c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running pipeline for LogisticRegression...\n",
      "\n",
      "Model Benchmark Results:\n",
      "\n",
      "Model               Train Time (s)    Latency (ms)    Model Size (KB) Accuracy (%)\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression           1.657            1.79                7.2        84.75\n",
      "\n",
      "Running pipeline for RandomForest...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     result = \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     print_result(name, result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(name, model)\u001b[39m\n\u001b[32m     19\u001b[39m start_time = time.perf_counter()\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1000\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Correct: 2D input\u001b[39;00m\n\u001b[32m     22\u001b[39m latency_ms = (time.perf_counter() - start_time) / \u001b[32m1000\u001b[39m * \u001b[32m1000\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# accuracy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mt:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:789\u001b[39m, in \u001b[36mPipeline.predict\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    787\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    788\u001b[39m         Xt = transform.transform(Xt)\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[32m    792\u001b[39m routed_params = process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m, **params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mt:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:903\u001b[39m, in \u001b[36mForestClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    883\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    884\u001b[39m \u001b[33;03m    Predict class for X.\u001b[39;00m\n\u001b[32m    885\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    901\u001b[39m \u001b[33;03m        The predicted classes.\u001b[39;00m\n\u001b[32m    902\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m     proba = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m:\n\u001b[32m    906\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classes_.take(np.argmax(proba, axis=\u001b[32m1\u001b[39m), axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mt:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:956\u001b[39m, in \u001b[36mForestClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    951\u001b[39m all_proba = [\n\u001b[32m    952\u001b[39m     np.zeros((X.shape[\u001b[32m0\u001b[39m], j), dtype=np.float64)\n\u001b[32m    953\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np.atleast_1d(\u001b[38;5;28mself\u001b[39m.n_classes_)\n\u001b[32m    954\u001b[39m ]\n\u001b[32m    955\u001b[39m lock = threading.Lock()\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msharedmem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimators_\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[32m    962\u001b[39m     proba /= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mt:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mt:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2070\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2064\u001b[39m \u001b[38;5;28mself\u001b[39m._call_ref = weakref.ref(output)\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2070\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mt:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1675\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1673\u001b[39m detach_generator_exit = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1674\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1675\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1676\u001b[39m     \u001b[38;5;66;03m# first yield returns None, for internal use only. This ensures\u001b[39;00m\n\u001b[32m   1677\u001b[39m     \u001b[38;5;66;03m# that we enter the try/except block and start dispatching the\u001b[39;00m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;66;03m# tasks.\u001b[39;00m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mt:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1658\u001b[39m, in \u001b[36mParallel._start\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1649\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator, pre_dispatch):\n\u001b[32m   1650\u001b[39m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[32m   1651\u001b[39m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[32m   1657\u001b[39m     \u001b[38;5;28mself\u001b[39m._iterating = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1658\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1659\u001b[39m         \u001b[38;5;28mself\u001b[39m._iterating = \u001b[38;5;28mself\u001b[39m._original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1661\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dispatch_one_batch(iterator):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mt:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1540\u001b[39m, in \u001b[36mParallel.dispatch_one_batch\u001b[39m\u001b[34m(self, iterator)\u001b[39m\n\u001b[32m   1538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1539\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mt:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1437\u001b[39m, in \u001b[36mParallel._dispatch\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m   1430\u001b[39m \u001b[38;5;28mself\u001b[39m._register_new_job(batch_tracker)\n\u001b[32m   1432\u001b[39m \u001b[38;5;66;03m# If return_ordered is False, the batch_tracker is not stored in the\u001b[39;00m\n\u001b[32m   1433\u001b[39m \u001b[38;5;66;03m# jobs queue at the time of submission. Instead, it will be appended to\u001b[39;00m\n\u001b[32m   1434\u001b[39m \u001b[38;5;66;03m# the queue by itself as soon as the callback is triggered to be able\u001b[39;00m\n\u001b[32m   1435\u001b[39m \u001b[38;5;66;03m# to return the results in the order of completion.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1437\u001b[39m job = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1438\u001b[39m batch_tracker.register_job(job)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mt:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\joblib\\_parallel_backends.py:339\u001b[39m, in \u001b[36mPoolManagerMixin.submit\u001b[39m\u001b[34m(self, func, callback)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[32m    336\u001b[39m \u001b[38;5;66;03m# Here, we need a wrapper to avoid crashes on KeyboardInterruptErrors.\u001b[39;00m\n\u001b[32m    337\u001b[39m \u001b[38;5;66;03m# We also call the callback on error, to make sure the pool does not\u001b[39;00m\n\u001b[32m    338\u001b[39m \u001b[38;5;66;03m# wait on crashed jobs.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.apply_async(\n\u001b[32m    340\u001b[39m     _TracebackCapturingWrapper(func),\n\u001b[32m    341\u001b[39m     (),\n\u001b[32m    342\u001b[39m     callback=callback,\n\u001b[32m    343\u001b[39m     error_callback=callback,\n\u001b[32m    344\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mt:\\dev\\Learn\\AI\\learn_ai\\.venv\\Lib\\site-packages\\joblib\\_parallel_backends.py:507\u001b[39m, in \u001b[36mThreadingBackend._get_pool\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Lazily initialize the thread pool\u001b[39;00m\n\u001b[32m    502\u001b[39m \n\u001b[32m    503\u001b[39m \u001b[33;03mThe actual pool of worker threads is only initialized at the first\u001b[39;00m\n\u001b[32m    504\u001b[39m \u001b[33;03mcall to apply_async.\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28mself\u001b[39m._pool = \u001b[43mThreadPool\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_n_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\pool.py:930\u001b[39m, in \u001b[36mThreadPool.__init__\u001b[39m\u001b[34m(self, processes, initializer, initargs)\u001b[39m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, processes=\u001b[38;5;28;01mNone\u001b[39;00m, initializer=\u001b[38;5;28;01mNone\u001b[39;00m, initargs=()):\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m     \u001b[43mPool\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\pool.py:215\u001b[39m, in \u001b[36mPool.__init__\u001b[39m\u001b[34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28mself\u001b[39m._processes = processes\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_repopulate_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\pool.py:306\u001b[39m, in \u001b[36mPool._repopulate_pool\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repopulate_pool\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_repopulate_pool_static\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_processes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inqueue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_outqueue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maxtasksperchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrap_exception\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\pool.py:329\u001b[39m, in \u001b[36mPool._repopulate_pool_static\u001b[39m\u001b[34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001b[39m\n\u001b[32m    327\u001b[39m w.name = w.name.replace(\u001b[33m'\u001b[39m\u001b[33mProcess\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPoolWorker\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    328\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m pool.append(w)\n\u001b[32m    331\u001b[39m util.debug(\u001b[33m'\u001b[39m\u001b[33madded worker\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\dummy\\__init__.py:51\u001b[39m, in \u001b[36mDummyProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._parent, \u001b[33m'\u001b[39m\u001b[33m_children\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mself\u001b[39m._parent._children[\u001b[38;5;28mself\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43mthreading\u001b[49m\u001b[43m.\u001b[49m\u001b[43mThread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:999\u001b[39m, in \u001b[36mThread.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    997\u001b[39m         \u001b[38;5;28;01mdel\u001b[39;00m _limbo[\u001b[38;5;28mself\u001b[39m]\n\u001b[32m    998\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m999\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_started\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    result = run_pipeline(name, model)\n",
    "    print_result(name, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
